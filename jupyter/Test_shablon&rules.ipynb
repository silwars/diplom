{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9a31e6-bea6-40cb-808b-06958d441bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1. Импорты и константы\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "BINNING_SPEC = {\n",
    "    'Total Fwd Packets':      ('uniform', 5),\n",
    "    'Total Backward Packets': ('uniform', 5),\n",
    "    'Total Length of Fwd Packets': ('uniform', 5),\n",
    "    'Total Length of Bwd Packets': ('uniform', 5),\n",
    "    'Active Mean':            ('uniform', 5),\n",
    "    'Idle Mean':              ('uniform', 5),\n",
    "    'Flow Duration':          ('uniform', 5)\n",
    "}\n",
    "\n",
    "SELECTED_COLS = [\n",
    "    'Total Fwd Packets','Total Backward Packets',\n",
    "    'Total Length of Fwd Packets','Total Length of Bwd Packets',\n",
    "    'Active Mean','Idle Mean','Flow Duration',\n",
    "    'Destination IP','Destination Port',\n",
    "    'FIN Flag Count','SYN Flag Count',\n",
    "    'RST Flag Count','PSH Flag Count','ACK Flag Count'\n",
    "]\n",
    "\n",
    "FEATURE_GROUPS = {\n",
    "    'network': [\n",
    "        'Destination IP','Destination Port',\n",
    "        'FIN Flag Count','SYN Flag Count',\n",
    "        'RST Flag Count','PSH Flag Count','ACK Flag Count'\n",
    "    ],\n",
    "    'temporal': ['Flow Duration'],\n",
    "    'traffic': [\n",
    "        'Total Fwd Packets','Total Backward Packets',\n",
    "        'Total Length of Fwd Packets','Total Length of Bwd Packets',\n",
    "        'Active Mean','Idle Mean'\n",
    "    ]\n",
    "}\n",
    "window_size = timedelta(minutes=30)\n",
    "slide_size  = timedelta(minutes=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcf168d-03a7-43d5-b70c-0b3cd66da138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2. Функции дискретизации и извлечения признаков\n",
    "\n",
    "def discretize_columns(df_in, spec, cols):\n",
    "    df2 = df_in[['Timestamp'] + cols].copy()\n",
    "    for col, (method, bins) in spec.items():\n",
    "        if col not in cols: continue\n",
    "        arr = df2[col].astype(float)\n",
    "        labels = [f\"bin{i}\" for i in range(bins)]\n",
    "        if method=='quantile':\n",
    "            b = pd.qcut(arr, q=bins, labels=labels, duplicates='drop')\n",
    "        else:\n",
    "            b = pd.cut(arr, bins=bins, labels=labels)\n",
    "        df2[col] = b.astype(str)\n",
    "    return df2\n",
    "\n",
    "def window_features(raw_win, disc_win):\n",
    "    feats = set()\n",
    "    for (_, r), (_, d) in zip(raw_win.iterrows(), disc_win.iterrows()):\n",
    "        for col in SELECTED_COLS:\n",
    "            if col in BINNING_SPEC:\n",
    "                feats.add(f\"{col}={d[col]}\")\n",
    "            else:\n",
    "                feats.add(f\"{col}={r[col]}\")\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e012bfb3-82fd-4330-aaeb-18fedbd24598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3. Загрузка данных и дискретизация\n",
    "\n",
    "# размеченный для оценки\n",
    "df_labeled   = pd.read_csv(\n",
    "    r'C:\\Users\\Гребенников Матвей\\Desktop\\Диплом\\Диплом\\Code\\diplom-project\\diplom\\test\\result\\Date\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX_sampled_v3.csv',\n",
    "    parse_dates=['Timestamp'])\n",
    "\n",
    "# неразмеченный для детекции\n",
    "df_unlabeled = pd.read_csv(\n",
    "    r'C:\\Users\\Гребенников Матвей\\Desktop\\Диплом\\Диплом\\Code\\diplom-project\\diplom\\test\\result\\Date\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX_sampled_v4.csv',\n",
    "    parse_dates=['Timestamp'])\n",
    "\n",
    "# дискретизируем оба фрейма\n",
    "df_disc_labeled = discretize_columns(df_labeled,   BINNING_SPEC, SELECTED_COLS)\n",
    "df_disc_unlabeled = discretize_columns(df_unlabeled, BINNING_SPEC, SELECTED_COLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0bd5ca-d35f-495d-8710-794301e69dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Всего DDoS строк: 30000, BENIGN строк: 70000\n",
      "[Info] Уникальных фич в DDoS: 28, в BENIGN: 21893\n"
     ]
    }
   ],
   "source": [
    "# ── Cell X: Считаем частоты фич в DDoS vs BENIGN ─────────────────────────────\n",
    "from collections import Counter\n",
    "\n",
    "# Подсчитаем, сколько строк каждого типа\n",
    "total_ddos   = (df_labeled['Label'] == 'DDoS').sum()\n",
    "total_benign = (df_labeled['Label'] == 'BENIGN').sum()\n",
    "\n",
    "# Собираем Counter-ы по признакам\n",
    "cnt_ddos   = Counter()\n",
    "cnt_benign = Counter()\n",
    "\n",
    "for idx, disc_row in df_disc_labeled.iterrows():\n",
    "    raw_label = df_labeled.at[idx, 'Label']\n",
    "    # полный набор фич текущей строки в формате \"Feature=binX\" или \"Feature=value\"\n",
    "    feats = {f\"{col}={disc_row[col]}\" for col in SELECTED_COLS}\n",
    "    if raw_label == 'DDoS':\n",
    "        cnt_ddos.update(feats)\n",
    "    elif raw_label == 'BENIGN':\n",
    "        cnt_benign.update(feats)\n",
    "\n",
    "print(f\"[Info] Всего DDoS строк: {total_ddos}, BENIGN строк: {total_benign}\")\n",
    "print(f\"[Info] Уникальных фич в DDoS: {len(cnt_ddos)}, в BENIGN: {len(cnt_benign)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ecd1e1-eaf0-4832-aae4-4a7500a51b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4. Построение окон (для labeled и unlabeled)\n",
    "\n",
    "windows = []  # список кортежей (raw_labeled, disc_unlabeled)\n",
    "cur = df_labeled['Timestamp'].min()\n",
    "end = df_labeled['Timestamp'].max()\n",
    "\n",
    "while cur + window_size <= end:\n",
    "    raw_l = df_labeled[\n",
    "        (df_labeled['Timestamp'] >= cur) & (df_labeled['Timestamp'] < cur + window_size)\n",
    "    ]\n",
    "    disc_u = df_disc_unlabeled[\n",
    "        (df_disc_unlabeled['Timestamp'] >= cur) & (df_disc_unlabeled['Timestamp'] < cur + window_size)\n",
    "    ]\n",
    "    windows.append((raw_l, disc_u))\n",
    "    cur += slide_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adecc984-1c44-4406-ada1-4de762b41769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load] Loaded 2862 CAR-rules\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 5b. Загрузка CAR-правил и Extended Top-K шаблонов + detect_attack ───\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Загружаем class-association rules (CAR) вида {A}⇒Label=DDoS или Label=BENIGN\n",
    "car_df = pd.read_csv('association_rules.csv')\n",
    "rules = []\n",
    "for _, r in car_df.iterrows():\n",
    "    A = set(x.strip() for x in r['Antecedent'].strip('{}').split(','))\n",
    "    B = r['Consequent']   # ожидаем \"Label=DDoS\" или \"Label=BENIGN\"\n",
    "    rules.append((A, B))\n",
    "print(f\"[Load] Loaded {len(rules)} CAR-rules\")\n",
    "\n",
    "# 2) Загружаем расширенный Top-K шаблон\n",
    "tmpl_df = pd.read_csv('attack_templates_topk_extended.csv')\n",
    "attack_templates = {}   # { attack: { group: set(feat_str) } }\n",
    "for _, row in tmpl_df.iterrows():\n",
    "    att = row['Attack']\n",
    "    grp = row['Group']\n",
    "    # row['Values'] имеет вид \"Flow Duration=bin0|bin3\" или \"Destination IP=192.168.10.50\"\n",
    "    colname, bins = row['Values'].split('=', 1)\n",
    "    bins = bins.split('|')\n",
    "    for b in bins:\n",
    "        feat = f\"{colname}={b}\"\n",
    "        attack_templates.setdefault(att, {}).setdefault(grp, set()).add(feat)\n",
    "\n",
    "# 3) Функция детектора по строковым CAR-правилам с учётом всех трёх групп\n",
    "def detect_attack(feats, min_rules=300):\n",
    "    \"\"\"\n",
    "    feats: set of \"Feature=val\" для одной строки.\n",
    "    Для атаки 'DDoS' требуем:\n",
    "      1) по крайней мере по одному feat из каждой группы network/temporal/traffic\n",
    "      2) ровно min_rules или больше CAR-правил вида A⇒Label=DDoS, где A⊆feats\n",
    "    Возвращает 'DDoS' или 'BENIGN'.\n",
    "    \"\"\"\n",
    "    # 1) групповая фильтрация\n",
    "    tmpl = attack_templates.get('DDoS', {})\n",
    "    for grp in FEATURE_GROUPS:\n",
    "        if not (tmpl.get(grp, set()) & feats):\n",
    "            return 'BENIGN'\n",
    "\n",
    "    # 2) считаем сколько DDoS-CAR-правил сработало\n",
    "    fired = 0\n",
    "    for A, B in rules:\n",
    "        if B == 'DDOS' and A.issubset(feats):\n",
    "            fired += 1\n",
    "\n",
    "    return 'DDoS' if fired >= min_rules else 'BENIGN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbfb715-b873-41d2-aca3-6f39ce4b92ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-level Precision: 0.82, Recall: 0.99\n",
      "TP=29556, FP=6449, TN=63551, FN=444\n",
      "Saved row_level_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 6. Row-level Evaluation (без окон) и сохранение результатов ─────────\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 6.1 Собираем строковые фичи для одной записи\n",
    "def row_features(raw, disc):\n",
    "    feats = set()\n",
    "    for col in SELECTED_COLS:\n",
    "        if col in BINNING_SPEC:\n",
    "            feats.add(f\"{col}={disc[col]}\")\n",
    "        else:\n",
    "            feats.add(f\"{col}={raw[col]}\")\n",
    "    return feats\n",
    "\n",
    "# Предполагается, что:\n",
    "#  - df_labeled и df_disc_labeled загружены и дискретизированы\n",
    "#  - функции и структуры из Cell 5b уже объявлены\n",
    "\n",
    "predictions = []\n",
    "TP = FP = TN = FN = 0\n",
    "\n",
    "for idx, raw in df_labeled.iterrows():\n",
    "    disc  = df_disc_labeled.loc[idx]\n",
    "    feats = row_features(raw, disc)\n",
    "    pred  = detect_attack(feats, min_rules=300)\n",
    "    true  = raw['Label']\n",
    "\n",
    "    # метрики\n",
    "    if pred == true:\n",
    "        if pred == 'DDoS': TP += 1\n",
    "        else:             TN += 1\n",
    "    else:\n",
    "        if pred == 'DDoS': FP += 1\n",
    "        else:             FN += 1\n",
    "\n",
    "    rec = raw.to_dict()\n",
    "    rec['Predicted'] = pred\n",
    "    predictions.append(rec)\n",
    "\n",
    "precision = TP / (TP + FP) if TP + FP else 0\n",
    "recall    = TP / (TP + FN) if TP + FN else 0\n",
    "print(f\"Row-level Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "print(f\"TP={TP}, FP={FP}, TN={TN}, FN={FN}\")\n",
    "\n",
    "# 6.2 Сохраняем все исходные строки + столбец Predicted\n",
    "pd.DataFrame(predictions).to_csv('row_level_predictions.csv', index=False)\n",
    "print(\"Saved row_level_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
